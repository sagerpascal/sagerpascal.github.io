---
layout: post
title:  EVA AI Seminar - Part 3 - Transformer Network
date: 2021-04-13
modified: 2021-04-13
categories: english MSc homework EVA-AI-seminar
comments: true
summary: This is the third post related to the course "EVA Artificial Intelligence Seminar". In this post, I describe what the Transformer network is, how it works and what its novelty is.
---

*This blogpost was created as a homework assignment in the [Artificial Intelligence seminar](https://moodle.msengineering.ch/mod/data/view.php?d=62&rid=3128&filter=1). In this assignment we have to write a blogpost in which we describe the content of a paper.*

# Transformer Network
I chose the Paper "Attention Is All You Need" [1] as my seminar literature. This paper was written by Vaswani et al. (members of Google
Brain and Google Research) and was presented at the 31st Conference on Neural Information Processing Systems (NIPS) in 2017.
It introduces a new architecture called "Transformer". Transformers are designed to handle sequential data like reccurent neural networks (RNNs). 
The main difference is that Transformers do not require that the sequential data be processed in order. For example, the beginning of an audio file
must not necessarily be processed before the end of the file. This allows Transformers much more parallelization than RNNs and therefore reduced training times.
This parallelization enables training on much larger datasets and has let to the development of huge systems such as GPT-3 [2] or BERT [3].

## Background
RNNs have been firmly established as state-of-the-art approaches in sequence modeling. Recurrent models have a "memory" in the sense that they
calculate a hidden state $$h_t$$ based on a previous hidden state $$h_{t-1}$$ and the input at time $$t$$. Since the hidden state $$h_t$$ is
used as one of the inputs to calculate the next hidden state $$h_{t+1}$$, the network can memorize part of the states. The disadvantage is
that not only the states but also the inputs must be processed sequentially. This precludes parallelization within training examples.

Together with RNNs, attention mechanisms were becoming more popular. An attention mechanism predicts for an input sequence which symbols are particularly interesting and should be paid more "attention".
However, these attention mechanism were always used in conjunction with RNN's. Transformer networks on the other hand, rely entirely on an attention mechanism.
They highlight the fact that the attention mechanisms alone, without recurrent sequential processing, are powerful enough to achieve the performance of RNNs with attention. This allows 
significantly more parallelization and therefore the usage of more data and/or faster training.

## Network Architecture
The model consists of a typical encoder-decoder architecture as shown in figure 1. The input signal is first converted in a vector, i.e. an input embedding.
Since the whole input is fed into the Transformer at once (and not sequentially), we have to add some information about the position. Otherwise the network
would not know anything about the positions of the single symbols, because everything is calculated in parallel. This is done using a positional encoding.
A positional encoding can be done using a combination of sinus and cosinus signals, which outputs a unique encoding for each time-step.

The input with the positional encoding is then fed into the encoder. Each layer in the encoder processes its input to generate encodings, 
containing information about which parts of the inputs are relevant to each other. This is done using an attention mechanism, which for each input, weighs the relevance of every other input and then produces a corresponding output.
Multiple encoder blocks can be combined - then each encoder block passes its set of encodings to the next block.

The decoder has the same number of blocks and does the opposite operation: Each layer takes all the encodings to generate an output sequence.
In comparison to the encoder, a decoder block consists of two attention mechanisms. The first attention mechanism  draws information from the outputs of previous decoders, 
the second one draws information from the corresponding encoder block.


<p align="center">
    <img src="/assets/images/posts/2021-03-22-EVA-Part3/transformer_architecture.PNG" alt="Transformer Architecture" width="60%" />
    <br>
    <i> Figure 1: The Transformer architecture (source: [1]).</i>
</p>

### An Explanatory Example
Now since the architecture is roughly known, let's illustrate the functionality with an example. A typical task of the sequence-to-sequence models is machine translation. Imagine we want to translate the English sentence "The AI seminar is great" into German using a Transformer network with two encoders and two decoder blocks. During training, both sentences are given, with the English sentence representing the given data and the German sentence representing the data to be predicted. First, we encode both sentences into symbols, i.e. feature vectors. Then we enrich these symbols with a positional encoding so that the network still knows that "The" was the first word, "AI" the second and so on. We do this for both sentences, the German and the English one. The English sentence is then fed into the encoder. The attention mechanisms are then used to calculate the attention of all words, given a specific word. For example, the word "seminar" will get a lot of attention for the word "The", because depending on the noun (i.e. "seminar"), the German translation of "The" is different (i.e. "der" or "die" or "das"). Since the encoder has two blocks, this is done twice. Afterwards, the encoded representations from the encoder block are fed into the corresponding decoder block. The decoder then decides based on the encoded representation which word would be the best translation. Given the english word "the", the decoder get some "hints" from the encoder to focus on "Seminar" and therefore should translate it to "das" (since it is called "das Seminar" in German and not "die Seminar" or "der Seminar"). This translation is done using not only one but two attention mechanism. The second one of them directly processes the encodings from the encoder, the first one the correct German translation shifted to the right. The German translation is shifted by 1, in order that the encoder not already sees the solution. This means, that if the first word is translated (i.e. "The") the input in the decoder is "None". Then the decoder should translate "The" to "Das", but of course he could get it wrong and translate it to "Der". After he has translated the word, the decoder sees the correct solution (i.e. "Das") and translates the next word. By doing so, the decoder can always rely on the correct translation despite one word and has therefore a stable training.

At inference time, this is done in the same way - but of course the German sentence is not know. The network then just translates one word. This word is then fed into the decoder and in the next loop the first two words get translated. This means that during inference time the words are processed sequentially, however this doesn't really hurt since we normally do not translate as many sentences as during training time.



## Application of Transformers

The paper on Transformer was published about 3.5 years ago. In the conclusion, the authors suggested that this type of network could also be interesting for other areas such as computer vision or audio processing (speaker recognition and speech recognition). This is reason enough to list a few exciting applications of transformer networks besides the typical NLP tasks like machine translation, document summarisation or document generation.

- Image Classification [4]
- Image Generation [5]
- Protein Prediction [6]
- Speech Recognition [7]
- Audio to Text [8]
- ...

If you want to learn more about these applications, I recommend reading the referenced papers. They are worth a look ;)


## Conclusion
In this blogpost, I rather tried to provide an intuition about the architecture than to explain everything in great detail. If you want to learn more about Transformer, especially how the Self-Attention Layers work in detail, I can only recommend to read the paper "Attention Is All You Need". This paper explains the architecture on a good abstraction level. It is written in a very understandable way, despite the high complexity of the architecture. For the implementation I recommend the use of the appropriate libraries, for example Torch Transformer of the Huggingface. But be careful, the devil is often in the details like the correct masking and shifting of the decoder input sequence.


- [1] Vaswani et al., "Attention Is All You Need", 2017, 31st Conference on Neural Information Processing Systems (NIPS)
- [2] Brown et al., "Language Models are Few-Shot Learners", 2020
- [3] Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", 2018
- [2] Dosovitskiy et al, "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", 2021, ICLR
- Parmar et al., "Image Transformer", 2018, PMLR
- Namibar et al., "Transforming the Language of Life: Transformer Neural Networks for Protein Prediction Tasks", 2020
- Chang et al. "End-to-End Multi-speaker Speech Recognition with Transformer", 2020
- Baevski et al., "wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations", 2020

