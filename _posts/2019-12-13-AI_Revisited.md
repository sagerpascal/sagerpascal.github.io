---
layout: post
title:  Artificial Intelligence - Revisited
date: 2019-12-13
modified: 2019-12-13
categories: german ai homework bachelor
comments: true
summary: Vor etwa 3 Monaten habe ich mich das erste Mal mit AI und den dazugehörigen Risiken auseinandergesetzt. In der Zwischenzeit habe ich einiges gelernt und entsprechend eine neue Ansicht zu diesem Thema. Ich denke viele Menschen schätzen AI falsch ein - in diesem Post möchte ich erklären wieso
---

*Dieser Blogeintrag entstand in Form eines Selbststudiums an der Zürcher Hochschule für Angewandte Wissenschaften*

### Mein erster Blog-Post

Vor gut 5 Monaten setze ich mich während dem Studium zum ersten Mal mit dem Thema auseinander. Ich studierte zu Beginn hauptsächlich, was künstliche Intelligenz ist und wieso angesehene Wissenschaftler vor dieser Technologie warnen. In meiner Recherche stiess ich auf die Theorie der Singularität von Raymon Kurzeil, Leiter der technischen Entwicklung bei Google. Zugegebenermassen, haben mich seine Aussagen zuerst schockiert, aber auch zum Nachdenken angeregt und ich habe mich stärker mit diesem Thema auseinandergesetzt und meine Erkenntnisse in meinem ersten [Blog-Post](https://sagerpascal.github.io/ict/2019/09/26/AI/) veröffentlicht. Nach den ersten Gehversuchen und dem Erarbeiten von neuem Wissen haben sich meine Gedanken zwar nicht radikal verändert, jedoch sehe ich einige Dinge nun gelassener und bin überzeugt, dass viele Leute AI falsch einschätzen. Solange nicht mit künstlicher Intelligenz gearbeitet wurde, denken viele an die Mythen aus Hollywood. So ähnlich wie ein Agent des Nachrichtendienstes sich im echten Leben nie James-Bond verhalten wird, so wird sich auch künstliche Intelligenz nicht wie menschenähnlicher, alleskönnender und superintelligener Roboter verhalten.



### Wieso wird AI falsch eingeschätzt?

Ich bin davon überzeugt, dass viele Menschen Angst vor AI haben, weil sie in Wahrheit nicht wissen, was dies genau ist. Ich denke, ähnlicher Ansicht ist auch Rodney Brooks, welcher am 6. Oktober 2017 den Bericht "The Seven Deadly Sins of AI Predictions - MIT Technology Review" veröffentlicht hat. Er nennt darin 7 Hauptgründe, wieso er denkt, dass sich viele Menschen zu unrecht vor der künstlichen Intelligenz fürchten:

- Überschätzen und Unterschätzen: Wir überschätzen, was für einen Effekt eine neue Technologie auf kurze Sicht haben wird und was für einen Effekt die Technologie auf lange Sicht haben wird
- Magie vorstellen: Wenn wir einer völlig neuen Technologie begegnen und wir nicht wissen wo deren Grenzen liegen, beginnen wir oft irgendwelche Fantasien auszumalen, was damit alles möglich wäre und am Ende stellt sich heraus, dass dies fernab jeglicher Realität ist.
- Performance vs. Kompetenz: Wenn ein System eine Aufgabe erfüllen konnte, dann gehen viele Menschen davon aus, dass diese Maschine auch ähnliche Dinge kann wie ein Mensch, der diese Aufgabe ebenfalls erfüllen kann.
- Suitcase Words: Wenn die Rede von einem lernfähigen System ist denken viele, dass dieses System wie wir lernt. Dies stimmt so aber nicht - die kleinste Veränderung in der Umgebung kann ein System völlig aus der Bahn werfen, nicht aber uns Menschen.
- Exponentielle Kurven: Viele Vorgänge werden als exponentiell beschrieben, beispielsweise der Zuwachs an Speicherkapazität auf derselben Fläche. Meist stimmt dies so aber nicht und der Wachstum wird an gewissen Stellen durch Grenzen limitiert
- Hollywood-Szenarien: Es wird nicht zu einem Szenario wie in Hollywood kommen - und schon gar nicht so plötzlich. Die Technologie wird sich laufend entwickeln, genauso die Intelligenz von Systemen. So werden wir uns daran gewöhnen und diese Systeme zu schätzen wissen und sie werden nicht von heute auf morgen plötzlich da sein.
- Geschwindigkeit der Entwicklung: Es dauert teilweise sehr lange, bis sich neue Technologien in der Industrie oder der "realen" Welt durchsetzen - Nur wenn etwas im Labor läuft, so wird dies nicht direkt angewendet werden. Die Technologie muss sich zuerst bewähren.



### Meine (leicht korrigierte) Meinung

Ich war in meinem ersten Block-Post schon davon überzeugt, dass ich es nicht mehr erleben werde, wie eine künstliche Superintelligenz geschaffen wird. Daran glaube ich auch heute noch, sogar noch stärker als zuvor. Ich persönlich sehe besonders den Schritt zu einer allgemeinen Intelligenz als sehr kritisch. Zu Beginn dachte ich immer, wenn ein System etwas gelernt hat, dann kann diese Fähigkeit einfach adaptiert werden. So ging ich davon aus, dass wenn beispielsweise ein System Autos auf einem Foto erkennen kann, dass System auch weiss, was ein Auto ist. Ich ging zwar nicht davon aus, dass das System dann erklären kann wie ein Auto funktioniert, aber beispielsweise dass es weiss, dass sich dieses bewegt oder Menschen transportieren kann. Für das System ist ein Auto jedoch kein Auto - es erkennt nur gewisse Muster auf einem Pixelhaufen (Bild).

Ein weiteres Beispiel wäre ein System welches Schach spielen kann. Würden beispielsweise die Regeln während des Spiels geändert werden und die Figuren könnten völlig andere Bewegungen durchführen, dann könnte das System dies nicht so adaptieren - und würde wohl auch gegen unerfahrene Spieler und nicht nur gegen Schachgrossmeister verlieren.

Es reicht nicht aus, einfach nur ein paar tausend kluge Algorithmen mit viel Rechenleistung und Speicherkapazität zu kombinieren. Die Maschine bräuchten ein grundsätzliches Verständnis für die Funktion der Welt so wie wir Menschen. Donald Knuth sagte einst:

> Die AI hat bisher fast alles erlernen können was denken erfordert - Jedoch fast nichts, was Menschen und Tiere ohne Nachdenken erledigen. <br>*(Donald Knuth, ehem. Professor an Stanford)*

Für mich persönlich stellt sich auch die Frage, ob ein System je im gleichen Sinne wie wir Menschen intelligent sein kann. Wir können zwar dem System beibringen, wie ein Auto aussieht oder dass sich dieses bewegen kann. Ob das System das Wort "fahren" jedoch so begreifen wird wie wir, daran zweifle ich, da das System diese Erfahrung des Autofahrens nie so mit allen Sinnen erleben kann wie wir Menschen.

Ich denke schlussendlich, dass wir vom Gedanken wegkommen müssen ein System zu entwickeln, dass alles kann wie ein Mensch. Das spannende an einer Intelligenz ist die Fähigkeit, gewisse Probleme für uns zu lösen, welche wir selbst nicht lösen können. Das System soll nicht dasselbe können wie wir, sondern uns unterstützen. 

Mir persönlich hat die Einführung in dieses Thema während dem Studium zum einen die Augen geöffnet, was alles möglich ist, zum anderen jedoch auch beruhigt, dass kein Szenario wie in Hollywood-Filmen eintreten wird. Ich glaube, dass die künstliche Intelligenz ein vielversprechendes Gebiet ist und uns grossen technischen Fortschritt bringen wird. Ich glaube jedoch auch, dass es beinahe unmöglich sein wird, eine generelle Intelligenz zu entwickeln. 







<u>Quellen:</u>

Artificial Intelligence: A modern Approach, Stuart Russell, Peter Norvig

[Rodney Brooks: “The Seven Deadly Sins of Predicting the Future of AI”, 20.11.2017](http://rodneybrooks.com/the-seven-deadly-sins-of-predicting-the-future-of-ai/)

[The AI Revolution: The Road to Superintelligence: Tim Urban, 22.01.2015](https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html)

[The Technews: AI could be the apocalypse for humans, warns Stephen Hawking!, 26.09.21019](http://thetechnews.com/2016/10/20/ai-could-be-the-apocalypse-for-humans-warned-by-stephen-hawking/)

[CNBC: Life with AI, 26.09.2019](https://www.cnbc.com/2018/03/13/elon-musk-at-sxsw-a-i-is-more-dangerous-than-nuclear-weapons.html)









