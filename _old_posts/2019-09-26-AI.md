---
layout: post
title:  Artificial Intelligence - Innovative Softwareprodukte oder die moderne Apokalypse?
date: 2019-09-20
modified: 2019-09-26
categories: german ai homework bachelor
comments: true
summary: Während dem Bachelorstudium habe ich mich zum ersten Mal mit künstlicher Intelligenz auseinandergesetzt und einen Bericht über die Risiken von AI gelesen. In diesem Post versuche ich aufzuzeigen, warum viele Menschen AI als Gefahr sehen.
---

*Dieser Blogeintrag entstand in Form eines Selbststudiums an der Zürcher Hochschule im Bezug auf Gefahren durch künstliche Intelligenz.*

# Was ist Artificial Intelligence?

Artificial Intelligence (dt. künstliche Intelligenz) ist zurzeit eines der gehyptesten Themen in der Informatikbranche. Doch was ist künstliche Intelligenz? Wikipedia beschreibt künstliche Intelligenz als

> "ein Teilgebiet der Informatik, welches sich mit der Automatisierung intelligenten Verhaltens und dem maschinellen Lernen befasst".

Ich persönliche finde dies eine gute Beschreibung, jedoch wird nicht darauf eingegangen, ab wann ein Verhalten als intelligent eingestuft werden kann. Frühere Definitionen bezogen sich oftmals auf den Menschen und sagten dass ein System sich intelligent verhält, wenn es eine Intelligenz wie ein Mensch aufweist oder so verhält. Dies ist wohl teilweise auf Alan Turing mit dessen Definition des Turing-Tests zurückzuführen, andererseits auch auf unsere Wahrnehmung, dass wir eine intelligente Spezies sind. 

Die Brüder Wright gelten als die Pioniere der Luftfahrt und haben sich zu Beginn von der Natur, genauer gesagt von Vögeln, inspirieren lassen - jedoch ohne Erfolg. Erst als sie ihr Denkmuster komplett angepasst und sie eine Gleitmaschine mit zwei langen Flügeln für den Auftrieb entwickelt hatten, kam der Erfolg. So ähnlich verhält es sich auch mit der künstlichen Intelligenz. Nur weil wir Menschen uns selber für klug halten, müssen wir nicht ein System entwickeln, dass sich verhält wie wir. Wir müssen nicht einen Vogel, sondern ein Flugzeug erschaffen.

Daher tendieren die neuen Definitionen von künstlicher Intelligenz nicht mehr hin zu menschlichem, sondern zu rationalem Verhalten. Ich selbst denke, dass ein System mit künstlicher Intelligenz etwas ist, dass uns mit seinen Fähigkeiten beeindruckt und somit auch im Kontext der Zeit betrachtet werden muss. Zum Beispiel als vor 80 Jahren der erste Computer entwickelt wurde und nur Experten verstanden wie damit tausende Berechnungen pro Sekunde durchgeführt werden konnten, hielten dieses System viele Bürger für äusserst intelligent. Heutzutage kann man damit niemanden mehr beeindrucken, denn jeder hat ein viel leistungsfähigeres Smartphone mit integriertem Taschenrechner für Berechnungen. - Und niemand spricht von künstlicher Intelligenz. Wir wiederum halten zurzeit selbstfahrende Autos für so klug, dass wir davon überzeugt sind, dass es sich dabei um künstliche Intelligenz handeln muss. Für künftige Generationen wird dies jedoch völlig normal und nichts speziellen sein - vielleicht halten sie uns sogar für lebensmüde Abenteurer weil wir das Auto selber gesteuert haben. Passend dazu ist auch die Aussage des berühmten AI-Pioniers John McCarthy welcher sagte: 

> "Sobald es funktioniert spricht niemand mehr von künstlicher Intelligenz." <br>*(John McCarthy, Informatiker, Erfinder von Lisp und AI-Pionier)*

# Artificial Intelligence - Die technische Apokalypse?

Viele berühmte Persönlichkeiten mit enormem technischem Fachwissen warnen uns vor AI. Zum Beispiel Elon Musk sagte während einer Konferenz: 

> Wir müssen super Vorsichtig sein mit AI. Möglicherweise ist die gefährlicher als Atombomben <br>*(Elon Musk, Gründer PayPal SpaceX und Tesla)*

Aber auch andere Forscher ohne Hintergrund in der Informatik warnen uns davor, beispielsweise Stephen Hawking:

> Die Entwicklung der vollen AI könnte das Ende der menschlichen Rasse bedeuten <br>*(Stephen Hawking, theoretischer Physiker und Astrophysiker)*

Es gibt natürlich noch unzählige weitere solcher Zitate von ebenso berühmten Persönlichkeiten unserer Zeit. Bei solchen Aussagen denken viele Leute an Filme in denen Roboter Böse werden, sich gegen den Menschen wenden und die Macht übernehmen wollen. Dies entspricht jedoch nicht den Vorstellungen der Skeptiker. Um deren Standpunkt zu erklären ist eine Unterteilung in drei verschiedene Arten von künstlicher Intelligenz nötig.

- Artificial Narrow Intelligence (ANI): Bei einer ANI handelt es sich um eine künstliche Intelligenz, die auf einem speziellen Gebiet eine erstaunliche Intelligenz aufweist wie beispielsweise dem Spielen von Schach oder dem autonomen Lenken eines Autos
- Artificial General Intelligence (AGI): Eine AGI ist in fast allen Gebieten so intelligent durchschnittlicher Mensch
- Artificial Superintelligence (ASI): Eine ASI ist den Menschen in fast allen Gebieten klar überlegen, und weist zugleich Allgemeinbildung Kreativität und soziale Fähigkeiten auf

Aktuell sind wir Menschen "nur" fähig eine ANI zu entwickeln, also ein System, dass in gewissen Bereichen erstaunliche Fähigkeiten aufweisen kann. Beispiele dafür sind Spamfilter in E-Mails, die Voraussage in Onlineshop "Leute die diesen Produkt gekauft haben mögen auch..." oder Apple's Siri. Davor fürchten sich wohl die wenigsten und es ist generell anerkannt, dass diese Technologie unser Leben positiv beeinflussen kann. Vielmehr fürchten sich einige Experten vor einer Artificial General Intelligence, also einem System, dass uns in vielen Bereichen ebenbürtig ist.

Wissenschaftliche Studien zeigen, dass die Lernkurve einer Intelligenz nicht linear, sondern exponentiell ist. Je mehr Wissen eine Gesellschaft hat, je einfacher wird es für sie, neues Wissen anzueignen. Anerkannte Forscher wie wie Raymond Kurzweil, der Leiter der technischen Entwicklung bei Google, gehen beispielsweise davon aus, dass wir Menschen im 21 Jahrhundert rund 1000 Mal mehr technischen Fortschritt erreichen können wie im 20. Jahrhundert. Dieses Verhalten, dass das Lernen mit mehr Wissen einfacher ist, trifft auch auf künstliche Intelligenz zu. Sobald ein AGI erreicht wird, also ein System das in etwa so klug ist wie wir, wird es für dieses viel einfacher sein, neues Wissen zu erlernen. Zu Beginn wird sie die Intelligenz eines Kleinkind aufweisen sich jedoch rasant entwickeln und schon bald die Intelligenz von einem Albert Einstein aufweisen - und an dieser Stelle kommt der kritische Punkt: Es kann zu einer Explosion des Wissens kommen. Das System ist nicht wie wir begrenzt. Es hat kein Gehirn, welches in einen Kopf eingeschlossen ist sondern beinahe unbegrenzte Rechenressourcen zu Verfügung. Es wird immer schlauer und wird immer besser wiessen, es lernen kann es ist entwickelt sich innerhalb von kurzer Zeit zu einer Artificial Superintelligence, ohne dass wir dem so richtig bewusst sind.

Viele Leute können sich nicht wirklich vorstellen, was eine Artificial Superintelligence ist. Es handelt sich dabei nicht um ein System, das so klug wie ein Mensch ist, aber einfach 1000 mal schneller denken kann. Es wird zwar mindestens 1000x schneller sein, der grosse Unterschied ist aber die Qualität der Intelligenz. Wenn wir einer Fliege ein Gehirn mit der gleichen Funktionalität  verpassen, einfach 1000 mal schneller, dann ist es noch lange nicht gleich schlau wie ein Mensch. Vielleicht hätte sie noch schnellere Reaktionszeiten aber sie würde trotzdem nicht verstehen, wie eine komplexe mathematische Rechnung durchgeführt werden kann. Wenn wir davon ausgehen, dass wir Menschen eine "Intelligenzstufen" über dem Affen stehen, dann wir die ASI wiederum über uns stehen. Jedoch nicht eine Stufe über uns, sondern mehrere hundert. Wir reden hier von einer Intelligenz, die nicht einen IQ von 140 hat, sondern vielleicht einen IQ von 14'867. Fragen an eine ASI, beispielsweise wie die Klimakatstrophe beseitig werden könnte, wäre für die ASI etwa so schwer zu beantworten wie für einen Mathematikprofessor was 1+1 ergibt. Die grösste Herausforderung für die ASI wäre es dann wohl noch unserer vergleichsweisen "dummen" Spezies beizubringen wie dies Funktioniert - Für die ASI wäre es wohl so als würden wir einer Ameise die Addition erklären.

Zurück zur Frage wieso das Persönlichkeiten wie Elon Musk oder Stephen Hawking uns vor der künstlichen Intelligenz, genauer gesagt vor der ASI warnen. Die Geschichte hat gezeigt, dass mit Wissen Macht kommt. Solch ein ASI wäre wohl das mächtigste System auf der Erde und verfolgt nur ein Ziel, nämlich das Ziel, welcher der Mensch bei seiner Entwicklung programmiert hat. Und genau darin liegt das Problem. Ein solches System verfügt über keine Moral. Hat es beispielsweise das Ziel das Klima zu retten wird es in der Lage sein, das grösste Problem zu erkennen - nämlichen den Menschen - und dieses allenfalls komplett beseitigen. Wir Menschen dürfen dabei auch nicht die Arroganz haben zu denken, dass wir es in einen Raum ohne Internetverbindung einsperren können und dann wohl schon nichts passieren wird. Für das System wäre es dank dessen enormen Intelligenzqualität etwa so schwer da rauszukommen, wie für uns Menschen uns aus einem Spinnennetz zu befreien.

Dies ist zumindest die Meinung von Experten wie Raymond Kurzweil der immerhin von Bill Gates als „führenden Experten im Bereich der Künstlichen Intelligenz“, oder vom Inc. Magazin als "Edisons rechtmässgen Erben" bezeichnet wird. Es gibt jedoch mindestens auch so viele Gegenstimmen, die nicht davon ausgehen, dass dieses Szenario so eintreffen wird. Entscheidend wird sein, wie sich die Artificial Superintelligence verhalten wird. Sie kann unser Leben sehr positiv jedoch auch äusserst negativ beeinflussen. Unbestritten ist jedoch, dass solch ein System unser Leben radikal verändern wird.

# AI - Doch alles nur halb so schlimm?

Es ist erwiesen, dass das Wissen exponentiell wächst und ich bin davon überzeugt, dass, wenn die Artificial General Intelligence erreicht wurde, es nur noch eine Frage der Zeit ist, bis die Artificial Superintelligence daraus entsteht. Jedoch liegt genau darin der Punkt. Zu einer solchen Wissensexplosion wird es nur kommen, wenn eine Artificial General Intelligence entwickelt werden kann. Ich will nicht ausschliessen, dass dies jemals der Fall sein wird, jedoch bin ich davon überzeugt, dass dies noch sehr viel Zeit in Anspruch nehmen wird und wir dies nicht mehr erleben dürfen (oder erleben müssen). Wir entwickeln zwar komplexe Computersysteme, deren Fähigkeiten sind jedoch meist sehr beschränkt und beziehen sich nur auf einzelne Aufgaben. Wir Menschen sind jedoch in der Lage zehntausende von verschiedenen Aufgaben durchzuführen. Es wird auch nicht ausreichen, zehntausend Systeme mit einer Fähigkeit zu entwickeln und dann zu kombinieren. Bei der AGI geht es um die Entwicklung eines Gesamtsystems, dass in allen Bereichen lernfähig ist und ich bin davon überzeugt, dass wir noch weit davon entfernt sind. Auch Donald Knuth, ein ehemaliger Professor an Stanford hat festgestellt, dass:

> Die AI hat bisher fast alles erlernen können was denken erfordert - Jedoch fast nichts, was Menschen und Tiere ohne Nachdenken erledigen. <br>*(Donald Knuth, ehem. Professor an Stanford)*

Daher bin ich davon überzeugt, dass AI, zumindest in naher Zukunft, nicht zum Weltuntergang führen wird, sondern vielmehr eine Technologie ist, welche korrekt eingesetzt unser Leben erleichtern kann. Wichtig dabei ist, nicht ein System zu entwickeln, dass die gleichen Fähigkeiten aufweist wie wir Menschen, sondern uns unterstützt. AI kann genutzt werden, um die Welt positiv zu beeinflussen, ohne dass wir uns vor dem Untergang fürchten müssen.

Zudem ist aus meiner Sich künstliche Intelligenz auch ein Begriff, welcher besonders durch das Marketing gefördert wird. Ein Produkt mit künstlicher Intelligenz verkauft sich nun mal besser als ein Produkt mit einem durchdachten Softwarealgorithmus. Künstliche Intelligenz ist aus meiner Sicht ein äusserst innovatives Artefakt aus einer Softwareentwicklung mit dem Potential sich auf dem Markt durchzusetzen. Und falls es sich wirklich durchzusetzen vermag, ist es in 100 Jahren so selbstverständlich, dass es niemand mehr als künstliche Intelligenz bezeichnen wird.


__Nachdem ich mich mehrere Monate mit AI auseinandergesetzt habe, hat sich auch meine persönliche Meinung verändert. Gerne könnt ihr mehr dazu lesen im Post [AI Revisited]({% post_url 2019-12-13-AI_Revisited %})__


### Quellen:

Artificial Intelligence: A modern Approach, Stuart Russell, Peter Norvig

[Cognitive Orthoses: Toward Human-Centered AI: Kenneth M. Ford, Patrick J. Hayes, Clark Glymour, James Allen, 2015](https://aaai.org/ojs/index.php/aimagazine/article/download/2629/2526)

[The AI Revolution: The Road to Superintelligence: Tim Urban, 22.01.2015](https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html)

[Wikipedia: Künstliche Intelligenz, 26.09.2019](https://de.wikipedia.org/wiki/Künstliche_Intelligenz)

[The Technews: AI could be the apocalypse for humans, warns Stephen Hawking!, 26.09.21019](http://thetechnews.com/2016/10/20/ai-could-be-the-apocalypse-for-humans-warned-by-stephen-hawking/)

[CNBC: Life with AI, 26.09.2019](https://www.cnbc.com/2018/03/13/elon-musk-at-sxsw-a-i-is-more-dangerous-than-nuclear-weapons.html)

[Wikipedia: Ray Kurzweil, 27.09.2019](https://en.wikipedia.org/wiki/Ray_Kurzweil)

[Enthusiasts and Skeptics Debate Artificial Intelligence](http://www.vanityfair.com/culture/2014/11/artificial-intelligence-singularity-theory)

[Terms of Ray Kurzweil and Mitch Kapor’s bet about the AI timeline: Kurt Andersen, 26.09.2019](http://longbets.org/1/)







